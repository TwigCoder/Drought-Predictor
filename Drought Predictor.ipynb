{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drought Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mission and Purpose\n",
    "\n",
    "Most scientists and software applications which focus on predicting areas that are likely to be affected by droughts, through the measurements and analysis of indexes such as the Standardized Precipitation Index (SPI) or the Palmer Drought Index (PDI), are focused on the United States and Europe. Additionally, they tend to focus on one nation or a subset of that nation. If any global efforts are underway, they remain to be relatively unknown.\n",
    "\n",
    "However, organizations have the data necessary to calculate the likelihood of droughts at locations around the world. For example, NASA has collected precipitation values at a global scale, which is the only information necessary to calculate the Standardized Precipitation Index. Thus, the purpose of my project is to create a Jupyter Notebook to determine where droughts are affecting the world in a readable format, such that this prototype will display the accurate information for the month of July in the year 2022 while allowing the scientific community to learn and build upon it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methodology\n",
    "\n",
    "I will be using an interactive map widget, provided by the ipywidgets, ipyleaflet, and leafmap Python packages, to show the status of locations in relation to the Standardized Precipitation Index. This index requires multiple precipitation values for each location in question. Thankfully, NASA readily provides this information from multiple years, with a new dataset available every month. As of now, the most recent dataset is from July 2022. My calculations used one dataset from every year for the years 2017 to 2022. However, the program was designed to be expandable, meaning that more and different datasets can be used, as long as they are from the same directory, due to the format of the code. You can find more information on this below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drought Project: The Code\n",
    "\n",
    "Now, I will code the project and create the interactive map. Numerous comments have been added to help others understand the design and functionality of the code.\n",
    "\n",
    "The interactive map widget can be viewed all the way at the bottom. First, you must run all of the cells. If there are any unresolved inputs, open the command prompt (administrative) and download the files using `pip` (ex. `pip install ipyleaflet`). Note that the `math` and `csv` packages are already included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports ##\n",
    "import ipyleaflet\n",
    "from ipyleaflet import Map, AwesomeIcon, Marker, SearchControl, LayerGroup, CircleMarker, basemaps, basemap_to_tiles\n",
    "import ipywidgets\n",
    "\n",
    "import math\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'moderately wet'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## SPI Calculator ##\n",
    "\n",
    "# SPI is a widely accepted index to calculate the intensity of drought.\n",
    "# Formula: SPI = (P - *P) / σp\n",
    "# P: precipitation\n",
    "# *P: mean precipitation\n",
    "# σp: Standard deviation of precipitation\n",
    "\n",
    "# This formula will take in a list of precipitation values.\n",
    "\n",
    "def calculate_spi(precipitation):\n",
    "    \n",
    "    # Calculate Variables P and *P\n",
    "    recent_precipitation = precipitation[-1]\n",
    "    mean_precipitation = sum(precipitation) / len(precipitation)\n",
    "    \n",
    "    # Calculate Standard Deviation\n",
    "    diff_list = []\n",
    "    for val in precipitation:\n",
    "        diff = val - mean_precipitation\n",
    "        diff_list.append(diff * diff)\n",
    "    sigma = sum(diff_list)\n",
    "    under_sqr_root = sigma / len(precipitation)\n",
    "    standard_deviation = math.sqrt(under_sqr_root)\n",
    "    \n",
    "    # Calculate SPI\n",
    "    numerator = recent_precipitation - mean_precipitation\n",
    "    denominator = standard_deviation\n",
    "    if denominator == 0:\n",
    "        spi = 0\n",
    "    else:\n",
    "        spi = numerator / denominator\n",
    "    return spi\n",
    "\n",
    "# Indexing the SPI Value\n",
    "# 2.0 and higher: Extremely wet\n",
    "# 1.5 ~ 1.99: Very Wet\n",
    "# 1.0 ~ 1.49: Moderately Wet\n",
    "# -.99 ~ .99: Near Normal\n",
    "# -1.49 ~ -1.0: Moderately Dry\n",
    "# -1.99 ~ -1.5: Severely Dry\n",
    "# -2 and less: Extremely Dry\n",
    "\n",
    "def spi_indexer(precipitation):\n",
    "    spi = calculate_spi(precipitation)\n",
    "    \n",
    "    # Indexer\n",
    "    if spi >= 2.0:\n",
    "        index = \"extremely wet\"\n",
    "    elif spi >=1.5:\n",
    "        index = \"very wet\"\n",
    "    elif spi >= 1:\n",
    "        index = \"moderately wet\"\n",
    "    elif spi > -1:\n",
    "        index = \"near normal\"\n",
    "    elif spi > -1.5:\n",
    "        index = \"moderately dry\"\n",
    "    elif spi > -2:\n",
    "        index = \"severely dry\"\n",
    "    elif spi <= -2:\n",
    "        index = \"extremely dry\"\n",
    "    else:\n",
    "        index = \"ERROR\"\n",
    "        print(\"Something went wrong when indexing. Please report this error.\")\n",
    "    \n",
    "    return index\n",
    "\n",
    "# Test Example\n",
    "spi_indexer([0, 1.2, 0.4, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read Data From CSV Files (Preprocess Data) ##\n",
    "\n",
    "# Create a list containing the names of the CSV files. The last one should be the most recent.\n",
    "file_names = [\"precip_2017.csv\", \"precip_2018.csv\", \"precip_2019.csv\", \"precip_2020.csv\", \"precip_2021.csv\", \"precip_2022.csv\"]\n",
    "\n",
    "# Get the latitude and longitude values.\n",
    "lat_vals = []\n",
    "max_v = -88.75\n",
    "while max_v <= 88.75:\n",
    "    lat_vals.append(max_v)\n",
    "    max_v += 2.5\n",
    "\n",
    "# NOTE: Longitude values are degrees to the east and latitude values are degrees north.\n",
    "\n",
    "lon_vals = []\n",
    "max_v = 1.25\n",
    "while max_v <= 358.75:\n",
    "    lon_vals.append(max_v)\n",
    "    max_v += 2.5\n",
    "\n",
    "# Get the precipitation values from each year. The format will be as such:\n",
    "# precip_dataset = [\n",
    "# [file_1],\n",
    "# [file_2],\n",
    "# ...\n",
    "# [most_recent_year]\n",
    "# ]\n",
    "\n",
    "# The files are formatted as such: Each row represents a latitude, starting at -88.75.\n",
    "# Each column represents a longitude, starting at 1.25. Thus, if we pull a precipitation\n",
    "# value from precip_dataset[1][8], it will be located at lat_vals[1] and long_vals[8].\n",
    "precip_dataset = []\n",
    "\n",
    "for file in file_names:\n",
    "    \n",
    "    annual_precip = []\n",
    "    \n",
    "    with open(f\"{file}\", mode ='r') as file:\n",
    "    \n",
    "        # reading the CSV file\n",
    "        csvFile = csv.reader(file)\n",
    "        \n",
    "        # displaying the contents of the CSV file\n",
    "        for lines in csvFile:\n",
    "            annual_precip.append(lines)\n",
    "    \n",
    "    precip_dataset.append(annual_precip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate and Plot ##\n",
    "\n",
    "# Center for the map.\n",
    "lat, lon = 27, -10\n",
    "\n",
    "# Create the map outline.\n",
    "theMap = ipyleaflet.Map(\n",
    "    center=(lat,lon),\n",
    "    zoom = 2,\n",
    "    zoom_snap = 0.5,\n",
    "    min_zoom = 2,\n",
    "    basemap = ipyleaflet.basemaps.Esri.WorldStreetMap,\n",
    "    draw_control=False,\n",
    "    measure_control=False,\n",
    "    fullscreen_control=False,\n",
    "    attribution_control=True,\n",
    "    toolbar_control = False)\n",
    "\n",
    "# Create the icons for all possible SPI indexes.\n",
    "icon_extremely_wet = AwesomeIcon(\n",
    "    marker_color='darkblue',\n",
    "    name = 'tint'\n",
    ")\n",
    "\n",
    "icon_very_wet = AwesomeIcon(\n",
    "    marker_color='blue',\n",
    "    name = 'tint'\n",
    ")\n",
    "\n",
    "icon_moderately_wet = AwesomeIcon(\n",
    "    marker_color='lightblue',\n",
    "    name = 'tint'\n",
    ")\n",
    "\n",
    "icon_near_normal = AwesomeIcon(\n",
    "    marker_color='beige',\n",
    "    name = 'tint'\n",
    ")\n",
    "\n",
    "icon_moderately_dry = AwesomeIcon(\n",
    "    marker_color='orange',\n",
    "    name = 'tint'\n",
    ")\n",
    "\n",
    "icon_severely_dry = AwesomeIcon(\n",
    "    marker_color='lightred',\n",
    "    name = 'tint'\n",
    ")\n",
    "\n",
    "icon_extremely_dry = AwesomeIcon(\n",
    "    marker_color='darkred',\n",
    "    name = 'tint'\n",
    ")\n",
    "\n",
    "# Calculate the SPI Index for each location and plot it on the map.\n",
    "for lati in range(0, len(lat_vals), 2):\n",
    "    for long in range(0, len(lon_vals), 2):\n",
    "        \n",
    "        precip_vals = []\n",
    "        for year in range(len(file_names)):\n",
    "            precip_vals.append(float(precip_dataset[year][lati][long]))\n",
    "\n",
    "        spi_index = spi_indexer(precip_vals)\n",
    "        \n",
    "        if spi_index == \"extremely wet\":\n",
    "            globals()[f\"marker_{lati}{long}\"] = Marker(location = (lat_vals[lati], [lon_vals[long] - 360 if lon_vals[long] > 180 else lon_vals[long]]), draggable = False, icon = icon_extremely_wet, title = \"Extremely Wet\", alt = \"Extremely Wet\")\n",
    "            theMap.add_layer(globals()[f\"marker_{lati}{long}\"])\n",
    "        \n",
    "        elif spi_index == \"very wet\":\n",
    "            globals()[f\"marker_{lati}{long}\"] = Marker(location = (lat_vals[lati], [lon_vals[long] - 360 if lon_vals[long] > 180 else lon_vals[long]]), draggable = False, icon = icon_very_wet, title = \"Very Wet\", alt = \"Very Wet\")\n",
    "            theMap.add_layer(globals()[f\"marker_{lati}{long}\"])\n",
    "            \n",
    "        elif spi_index == \"moderately wet\":\n",
    "            globals()[f\"marker_{lati}{long}\"] = Marker(location = (lat_vals[lati], [lon_vals[long] - 360 if lon_vals[long] > 180 else lon_vals[long]]), draggable = False, icon = icon_moderately_wet, title = \"Moderately Wet\", alt = \"Moderately Wet\")\n",
    "            theMap.add_layer(globals()[f\"marker_{lati}{long}\"])\n",
    "            \n",
    "        elif spi_index == \"near normal\":\n",
    "            globals()[f\"marker_{lati}{long}\"] = Marker(location = (lat_vals[lati], [lon_vals[long] - 360 if lon_vals[long] > 180 else lon_vals[long]]), draggable = False, icon = icon_near_normal, title = \"Near Normal\", alt = \"Near Normal\")\n",
    "            theMap.add_layer(globals()[f\"marker_{lati}{long}\"])\n",
    "            \n",
    "        elif spi_index == \"moderately dry\":\n",
    "            globals()[f\"marker_{lati}{long}\"] = Marker(location = (lat_vals[lati], [lon_vals[long] - 360 if lon_vals[long] > 180 else lon_vals[long]]), draggable = False, icon = icon_moderately_dry, title = \"Moderately Dry\", alt = \"Moderately Dry\")\n",
    "            theMap.add_layer(globals()[f\"marker_{lati}{long}\"])\n",
    "            \n",
    "        elif spi_index == \"severely dry\":\n",
    "            globals()[f\"marker_{lati}{long}\"] = Marker(location = (lat_vals[lati], [lon_vals[long] - 360 if lon_vals[long] > 180 else lon_vals[long]]), draggable = False, icon = icon_severely_dry, title = \"Severely Dry\", alt = \"Severely Dry\")\n",
    "            theMap.add_layer(globals()[f\"marker_{lati}{long}\"])\n",
    "            \n",
    "        elif spi_index == \"extremely dry\":\n",
    "            globals()[f\"marker_{lati}{long}\"] = Marker(location = (lat_vals[lati], [lon_vals[long] - 360 if lon_vals[long] > 180 else lon_vals[long]]), draggable = False, icon = icon_extremely_dry, title = \"Extremely Dry\", alt = \"Extremely Dry\")\n",
    "            theMap.add_layer(globals()[f\"marker_{lati}{long}\"])\n",
    "\n",
    "# Create the legend.\n",
    "legend = ipyleaflet.LegendControl({\"Extremely Wet\":\"#005998\", \"Very Wet\":\"#0098e2\", \"Moderately Wet\":\"#61eeff\", \"Near Normal\": \"#FFCC99\", \"Moderately Dry\": \"#FF9966\", \"Severely Dry\": \"#FAA\", \"Extremely Dry\" : \"#8B0000\"}, name=\"Legend\", position = \"topright\")\n",
    "theMap.add_control(legend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "648ea4f42ea24cfaaa2baac5fa87255e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[27, -10], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'zoom_out_te…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "theMap "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b6213e0af081d56db034f795ff49d96980936e2ae540dda57fc6c3cbea6a5fc9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
